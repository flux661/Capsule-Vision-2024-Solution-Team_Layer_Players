# -*- coding: utf-8 -*-
"""btp_newapproach_final_model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qXDwBPheYMh7xwlAjXrAO4TcRs-9X85O
"""

from google.colab import drive
drive.mount('/content/drive')

!unzip /content/drive/MyDrive/Dataset.zip -d /content/

# How many images in each folder
import os

# Walk through the data
for dirpath,dirnames,filenames in os.walk("Dataset"):
  print(f"There are {len(dirnames)} directories and {len(filenames)} images in {dirpath}.")

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import numpy as np
import os
from collections import Counter
from sklearn.utils import shuffle
from tensorflow.keras.utils import Sequence

class BalancedImageDataGenerator:
    def __init__(self, target_samples=5000, **kwargs):
        self.target_samples = target_samples
        self.image_data_generator = ImageDataGenerator(**kwargs)

    def flow_from_directory(self, directory, **kwargs):
        # First, get the base generator
        base_generator = self.image_data_generator.flow_from_directory(
            directory,
            shuffle=False,
            **kwargs
        )

        # Get all filenames and their corresponding labels
        filenames = base_generator.filenames
        labels = base_generator.classes
        class_indices = base_generator.class_indices
        n_classes = len(class_indices)

        # Count samples per class
        class_counts = Counter(labels)

        # Create balanced dataset
        balanced_filenames = []
        balanced_labels = []

        for class_idx in range(n_classes):
            class_files = [f for f, l in zip(filenames, labels) if l == class_idx]
            class_count = len(class_files)

            if class_count >= self.target_samples:
                # Undersample
                selected_files = shuffle(class_files)[:self.target_samples]
            else:
                # Oversample
                multiplier = self.target_samples // class_count
                remainder = self.target_samples % class_count
                selected_files = class_files * multiplier + shuffle(class_files)[:remainder]

            balanced_filenames.extend(selected_files)
            balanced_labels.extend([class_idx] * self.target_samples)

        # Shuffle the balanced dataset
        balanced_filenames, balanced_labels = shuffle(balanced_filenames, balanced_labels)

        class BalancedGenerator(Sequence):
            def __init__(self, parent, filenames, labels, directory, **kwargs):
                self.parent = parent
                self.filenames = filenames
                self.labels = labels
                self.directory = directory
                self.n = len(filenames)
                self.batch_size = kwargs.get('batch_size', 32)
                self.target_size = kwargs.get('target_size', (224, 224))
                self.shuffle = kwargs.get('shuffle', True)
                self.indices = np.arange(self.n)
                self.class_indices = class_indices

                if self.shuffle:
                    np.random.shuffle(self.indices)

            def __len__(self):
                return int(np.ceil(self.n / float(self.batch_size)))

            def __getitem__(self, idx):
                start_idx = idx * self.batch_size
                end_idx = min((idx + 1) * self.batch_size, self.n)
                batch_indices = self.indices[start_idx:end_idx]

                batch_files = [os.path.join(self.directory, self.filenames[i]) for i in batch_indices]
                batch_labels = [self.labels[i] for i in batch_indices]

                # Load and preprocess images
                batch_images = []
                for f in batch_files:
                    # Load image
                    img = tf.keras.utils.load_img(f, target_size=self.target_size)
                    # Convert to array
                    img_array = tf.keras.utils.img_to_array(img)
                    # Apply standardization
                    img_array = self.parent.image_data_generator.standardize(img_array)
                    # Apply random transformations
                    img_array = self.parent.image_data_generator.random_transform(img_array)
                    batch_images.append(img_array)

                batch_images = np.array(batch_images)

                # Convert labels to categorical
                batch_labels = tf.keras.utils.to_categorical(batch_labels, n_classes)

                return batch_images, batch_labels

            def on_epoch_end(self):
                if self.shuffle:
                    np.random.shuffle(self.indices)

        return BalancedGenerator(self, balanced_filenames, balanced_labels, directory, **kwargs)

# Usage:
balanced_train_datagen = BalancedImageDataGenerator(
    target_samples=5000,
    rescale=1./255,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

balanced_val_datagen = BalancedImageDataGenerator(
    target_samples=5000,
    rescale=1./255
)

train_dir = '/content/Dataset/training'
val_dir = '/content/Dataset/validation'

train_generator = balanced_train_datagen.flow_from_directory(
    train_dir,
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical'
)

validation_generator = balanced_val_datagen.flow_from_directory(
    val_dir,
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical'
)

"""**BUILD RESNET101 WITH SQUEEZE AND EXCITATION BLOCKS**"""

import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.applications import ResNet101

# Squeeze-and-Excitation Block
def se_block(input_tensor, ratio=16):
    channel_axis = 3  # Channels last format
    filters = input_tensor.shape[channel_axis]

    se = layers.GlobalAveragePooling2D()(input_tensor)
    se = layers.Reshape((1, 1, filters))(se)
    se = layers.Dense(filters // ratio, activation='relu')(se)
    se = layers.Dense(filters, activation='sigmoid')(se)

    return layers.multiply([input_tensor, se])

# Adding SE blocks to ResNet101
def build_resnet101_se(input_shape=(224, 224, 3), num_classes=10):
    base_model = ResNet101(include_top=False, input_shape=input_shape, weights='imagenet')
    x = base_model.output

    # Adding SE blocks at every stage
    for layer in base_model.layers:
        if isinstance(layer, layers.Conv2D):
            x = se_block(layer.output)

    x = layers.GlobalAveragePooling2D()(x)
    x = layers.Dense(512, activation='relu')(x)  # Fully connected layer
    x = layers.Dropout(0.5)(x)
    output = layers.Dense(num_classes, activation='softmax')(x)

    model = models.Model(inputs=base_model.input, outputs=output)

    return model

# Build model
model = build_resnet101_se()

# Compile model
model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.00001), loss='categorical_crossentropy', metrics=['accuracy'])

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import numpy as np
import os
from collections import Counter
from sklearn.utils import shuffle
from tensorflow.keras.utils import Sequence

class BalancedImageDataGenerator:
    def __init__(self, target_samples=5000, balance_classes=True, **kwargs):
        self.target_samples = target_samples
        self.balance_classes = balance_classes
        self.image_data_generator = ImageDataGenerator(**kwargs)

    def flow_from_directory(self, directory, **kwargs):
        # First, get the base generator
        base_generator = self.image_data_generator.flow_from_directory(
            directory,
            shuffle=False,
            **kwargs
        )

        # Get all filenames and their corresponding labels
        filenames = base_generator.filenames
        labels = base_generator.classes
        class_indices = base_generator.class_indices
        n_classes = len(class_indices)

        if not self.balance_classes:
            # If not balancing, just use original filenames and labels
            balanced_filenames = filenames
            balanced_labels = labels
        else:
            # Create balanced dataset
            balanced_filenames = []
            balanced_labels = []

            # Count samples per class
            class_counts = Counter(labels)

            for class_idx in range(n_classes):
                class_files = [f for f, l in zip(filenames, labels) if l == class_idx]
                class_count = len(class_files)

                if class_count >= self.target_samples:
                    # Undersample
                    selected_files = shuffle(class_files)[:self.target_samples]
                else:
                    # Oversample
                    multiplier = self.target_samples // class_count
                    remainder = self.target_samples % class_count
                    selected_files = class_files * multiplier + shuffle(class_files)[:remainder]

                balanced_filenames.extend(selected_files)
                balanced_labels.extend([class_idx] * len(selected_files))

        # Shuffle the dataset
        balanced_filenames, balanced_labels = shuffle(balanced_filenames, balanced_labels)

        class DataGenerator(Sequence):
            def __init__(self, parent, filenames, labels, directory, **kwargs):
                self.parent = parent
                self.filenames = filenames
                self.labels = labels
                self.directory = directory
                self.n = len(filenames)
                self.batch_size = kwargs.get('batch_size', 32)
                self.target_size = kwargs.get('target_size', (224, 224))
                self.shuffle = kwargs.get('shuffle', True)
                self.indices = np.arange(self.n)
                self.class_indices = class_indices

                if self.shuffle:
                    np.random.shuffle(self.indices)

            def __len__(self):
                return int(np.ceil(self.n / float(self.batch_size)))

            def __getitem__(self, idx):
                start_idx = idx * self.batch_size
                end_idx = min((idx + 1) * self.batch_size, self.n)
                batch_indices = self.indices[start_idx:end_idx]

                batch_files = [os.path.join(self.directory, self.filenames[i]) for i in batch_indices]
                batch_labels = [self.labels[i] for i in batch_indices]

                # Load and preprocess images
                batch_images = []
                for f in batch_files:
                    # Load image
                    img = tf.keras.utils.load_img(f, target_size=self.target_size)
                    # Convert to array
                    img_array = tf.keras.utils.img_to_array(img)
                    # Apply standardization
                    img_array = self.parent.image_data_generator.standardize(img_array)
                    # Apply random transformations
                    img_array = self.parent.image_data_generator.random_transform(img_array)
                    batch_images.append(img_array)

                batch_images = np.array(batch_images)

                # Convert labels to categorical
                batch_labels = tf.keras.utils.to_categorical(batch_labels, n_classes)

                return batch_images, batch_labels

            def on_epoch_end(self):
                if self.shuffle:
                    np.random.shuffle(self.indices)

        return DataGenerator(self, balanced_filenames, balanced_labels, directory, **kwargs)

# Usage:
# Training generator with balancing
balanced_train_datagen = BalancedImageDataGenerator(
    target_samples=5000,
    balance_classes=True,  # Enable balancing for training
    rescale=1./255,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

# Validation generator without balancing
val_datagen = BalancedImageDataGenerator(
    balance_classes=False,  # Disable balancing for validation
    rescale=1./255
)

train_generator = balanced_train_datagen.flow_from_directory(
    train_dir,
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical'
)

validation_generator = val_datagen.flow_from_directory(
    val_dir,
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical'
)

history = model.fit(train_generator,
                    validation_data = validation_generator,
                    epochs=20,
                    callbacks=[
                        tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True),
                        tf.keras.callbacks.ReduceLROnPlateau(factor=0.2, patience=3)
                    ])

import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
from sklearn.metrics import balanced_accuracy_score,f1_score


# Set the limit on the number of batches to process
num_batches = 505

# Step 1: Generate predictions for a limited number of batches
val_predictions = []
val_true_classes = []

for i, (x, y) in enumerate(validation_generator):
    preds = resnet_model.predict(x)
    # print(preds.keys())
#     print(preds['output_0'])
    val_predictions.append(np.argmax(preds['output_0'], axis=1))
    val_true_classes.append(np.argmax(y, axis=1))
    if i >= 504:
      break;

# Step 2: Concatenate predictions and true labels across batches
val_pred_classes = np.concatenate(val_predictions)
val_true_classes = np.concatenate(val_true_classes)

print(val_true_classes.shape,val_pred_classes.shape)

# Evaluation function
def evaluate_predictions(y_true, y_pred):
    # y_true_classes = np.argmax(y_true, axis=1)
    # y_pred_classes = np.argmax(y_pred, axis=1)

    # Calculate balanced accuracy and F1 score
    bal_acc = balanced_accuracy_score(y_true_classes, y_pred_classes)
    f1 = f1_score(y_true_classes, y_pred_classes, average='weighted')

    return bal_acc, f1

# Evaluate predictions
bal_acc, f1 = evaluate_predictions(val_true_classes, val_pred_classes)
print(f"Ensemble Model - Balanced Accuracy: {bal_acc:.4f}, F1-Score: {f1:.4f}")

# Step 3: Compute the confusion matrix
conf_matrix = confusion_matrix(val_true_classes, val_pred_classes)

# Step 4: Plot the confusion matrix
disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix)
disp.plot(cmap=plt.cm.Blues)
plt.title("Confusion Matrix (Limited to 505 Batches)")
plt.show()



# Save the model in SavedModel format
model.export('/content/drive/MyDrive/models/resnet_modified_Kaist')





